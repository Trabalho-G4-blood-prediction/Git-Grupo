{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inicialização.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1DIFhTIoKO4v-ohzCc0MfdT-9clK7SAdm","authorship_tag":"ABX9TyPrYcBrtP/T9Lht6ADWPDa/"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"_vb8eZDBdFOa","executionInfo":{"status":"ok","timestamp":1618330524508,"user_tz":180,"elapsed":859,"user":{"displayName":"Felipe Navarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmdBe4rTCFWx5-agZ7yNxvLwlX2BCyDHL0Xnak=s64","userId":"17557421270393561228"}}},"source":["import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":76},"id":"srA3YPAIdHm6","executionInfo":{"status":"ok","timestamp":1618330524817,"user_tz":180,"elapsed":1159,"user":{"displayName":"Felipe Navarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmdBe4rTCFWx5-agZ7yNxvLwlX2BCyDHL0Xnak=s64","userId":"17557421270393561228"}},"outputId":"2f2566c8-a1ea-4e52-8236-3299c4dfc291"},"source":["#Importando o DataFrame\n","df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Trabalho em grupo/Limpa_G4\")\n","df = df.iloc[:,1:]\n","df\n","\n","# Separando X e y \n","X = df.iloc[:,:-1]\n","y = df.iloc[:,-1]\n","\n","#Separando os dados em teste e treino\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, stratify = y,  random_state= 6)\n","\n","#Separando os dados de treinamento em treinamento (final) e validação\n","\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.20, stratify = y_train, random_state= 6)\n","\n","# Calculando as proporções do valor 1 entre os splits\n","prop_real = df[df[\"Made Donation in March 2007\"] == 1][\"Made Donation in March 2007\"].count()/df[\"Made Donation in March 2007\"].count()\n","prop_treino = y_train[y_train == 1].count()/y_train.count()\n","prop_teste = y_test[y_test == 1].count()/y_test.count()\n","prop_validação = y_val[y_val == 1].count()/y_val.count()\n","\n","# Criando um Data Frame para avaliar se a proporção de valor 1 é identica nos datasets.\n","df_train_test_prop = pd.DataFrame([prop_real,prop_treino,prop_teste, prop_validação]).T\n","df_train_test_prop.rename(columns = {0:\"Proporção Real\", 1: \"Proporção de Treinamento\", 2: \"Proporção de Teste\", 3: \"Proporção de Validação\"}, \n","                          inplace = True)\n","df_train_test_prop"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Proporção Real</th>\n","      <th>Proporção de Treinamento</th>\n","      <th>Proporção de Teste</th>\n","      <th>Proporção de Validação</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.237968</td>\n","      <td>0.238189</td>\n","      <td>0.238938</td>\n","      <td>0.23622</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Proporção Real  ...  Proporção de Validação\n","0        0.237968  ...                 0.23622\n","\n","[1 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"code","metadata":{"id":"HRVnHheqdxCB","executionInfo":{"status":"ok","timestamp":1618330524818,"user_tz":180,"elapsed":1158,"user":{"displayName":"Felipe Navarro","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgmdBe4rTCFWx5-agZ7yNxvLwlX2BCyDHL0Xnak=s64","userId":"17557421270393561228"}}},"source":["# Normalizando X_train\n","\n","scaler = MinMaxScaler()\n","scaler.fit(X_train)\n","X_train = scaler.transform(X_train)\n","\n","# Normalizando o resto\n","\n","X_val = scaler.transform(X_val)\n","X_test = scaler.transform(X_test)"],"execution_count":10,"outputs":[]}]}